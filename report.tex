\documentclass{article} % For LaTeX2e
\usepackage{nips15submit_e,times}
\usepackage{hyperref}
\usepackage{url}


\title{Activity Recognition Analysis for Discriminating Weight Lifting Exercises}


\author{
Wenzhen Gong \\
School of Computing Science\\
Simon Fraser University\\
Burnaby, BC, Canada V5A 1S6 \\
\texttt{wenzheng@sfu.ca} \\
\And
Tianhan Zhang \\
School of Computing Science\\
Simon Fraser University\\
Burnaby, BC, Canada V5A 1S6 \\
\texttt{tianhanz@sfu.ca} \\
\AND
Kathy Yan Shi \\
School of Computing Science\\
Simon Fraser University\\
Burnaby, BC, Canada V5A 1S6 \\
\texttt{yshi2@sfu.ca} \\
\And
Dongyuan Liu \\
School of Computing Science\\
Simon Fraser University\\
Burnaby, BC, Canada V5A 1S6 \\
\texttt{dla126@sfu.ca} \\
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\nipsfinalcopy % Uncomment for camera-ready version

\begin{document}


\maketitle

\begin{abstract}
Activity recognition has been traditionally focusing on identification of different activities. Our research is focusing on analyzing quality of executing certain activities.
\end{abstract}

\section{Introduction}

Physical exercises offer tremendous benefits to improve the qualities of people’s lives. However, improper activities may cause injuries and lead to long term sufferings. Especially in weight trainings, risk of injuries gets higher compare to other exercises [1]. Therefore, identifying the correct movement in each repetition of weight exercises helps to improve the quality of training and prevent the chances of injuries. However, the key challenge is discriminating the proper movements against those improper ones without a professional trainer. Our research applies machine learning classification techniques to automatically assess the quality of each bicep weight lifting activity.

Our dataset is from Weight Lifting Exercises monitored with Inertial Measurement Units Dataset in UCI Repository. The dataset contains on-body sensing data of six young healthy participants performing one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions, among which one is correct and the rest four is wrong.

During the training stage, we compared the performances between feeding the preprocessed data and semi raw data, and conducted different experiments on the following classification models: Variations of Random Assignment, Perception Method, Parzen-Window Density Estimation, K-Nearest Neighbour Algorithm, and Support Vector Machine. During the testing stage, we performed two types of testings: Testing new activities on existing subject, and testing new activities on new subjects. Figure 1 illustrates the workflow we conducted during our study of activity recognition.

Velloso \textit{et al.} conducted activity recognition study on the same dataset in 2013 to distinguish the five classes of activities. Their work also intends to automatically assess the quality of weight lifting activities [2]. However, they focus on three key components of quality activity recognition, which are specifying the correct execution, detecting execution mistakes, and providing feedback on users [2]. The classification model they constructed was applied by leveraging Random Forest approach with  “Banging” method [2].

TODO: workflow figure

Other than study the three key components of qualitative activity recognition, we conducted our experiment in a different perspective to explore the breadth of classification algorithms. Our study focuses on analyzing different classification results conducted by different classification models. Our ultimate goal is to be able to distinguish correct activities as well as different wrong activities.

\section{Approach}

\subsection{Data Pre-processing}

Our dataset contains 152 dimensions and 39422 instances. The data pre-processing stage includes transforming categorical data into numerical data, filling and removing sparse data cells, normalizing data, and reducing dimensions. Sparse cells were filled with their corresponding statistical data, such as min, max, mean, and variance. All the numerical data was normalized to have mean zero 0 and covariance 1. Moreover, feature exaction was handled by Principal Component Analysis (PCA) to reduce the dimensions. After we pre-processed the data, the data was reduced to 50 dimensions other than 152.

\subsection{Training Algorithms}

Our training approaches are based on sklearn library written in Python. In this section we will discuss different training algorithms we applied in our project. The following table should provide a general overview about our approaches.

\subsubsection{Random Assignment}

In this approach, we assign a data instance to a random class. Every class has equal probability to be assigned to. Since we have five classes in total, this means every class has 20\% probability to be assigned to. However, as we already know that the distributions of different classes in our data set are different, we do not expect high performance from it. Instead, we will only use it as a benchmark for comparison.

\subsubsection{Random Assignment I}

In our second randomized approach, we also assign a data instance to a class randomly. However, unlike the first random approach, we take the original distribution of different classes in our training data set into considerations. That means different classes have different probabilities to be assigned to. For example, Class 0 is 27.9\% of  training data, therefore, for a testing data instance, it has 27.9\% possibility to be assigned to Class 0. The rest four classes’ possibilities follow the same idea.

\subsubsection{Random Assignment II}

Our third randomized approach is rather simple comparing the previous two. In this approach, we blindly assign all the testing instances to Class 0, which has the highest frequency in the entire data set. Hence, the performance of this approach is within a predictable range. With the test cases we randomly selected for existing subjects, both the semi raw data and the normalized data have 28.63\% accuracy. For new subject, the accuracy rate is 33.56\%.

\subsubsection{Baseline}

In baseline approach, we applied an algorithm which borrows the idea of k nearest neighbour. We use all of our training data to generate five centers of  five classes. For the testing instances, we assignment them to the class with the closest center to them.

\subsubsection{K Nearest Neighbours}

In this training algorithm, we assign a testing instance to a class based on its K nearest neighbours. Among the K nearest neighbours, we find the class, which most of the training instances belong to, then assign the testing instance to that class. In terms of choice of K, we have tried multiple values, among which we found that the square root of total amount of training data gives the best outcome. This specific comes from one of our team members’ previous project experience.

\subsubsection{Parzen-Window}

Parzen-Window approach has very similar idea to K nearest neighbours approach, but also slightly different from it. In parzen-window approach, we focus more on the density of data instances around the testing data. In this case, we exam an area instead of a certain number of neighbours. After we decide the radius of the area we should be looking at, we pick the class that has majority number of instances within that area and assign our testing data to that class. That being said, with different settings of radius R, assignment of classes could be quite different. It is also possible that certain data instance does not have any training data instance within R. Therefore, we will have outliers. In this project and for this approach, we set all outliers to be Class 0, which is the major class in our training data.

\subsubsection{Perceptron and SVM}

In this project, we also included basic machine learning algorithms, such as perceptron and SVM. Since the training phase is based on sklearn package in Python, we used the library’s perceptron and SVM functions. For perceptron, instead of using default 5 times of passes over the training data, we set n\_iter to 1000 and left the rest arguments as default. For SVM, we set the kernel argument as linear instead of the default rbf setting.

\section{Citations, figures, tables, references}
\label{others}

These instructions apply to everyone, regardless of the formatter being used.

\subsection{Citations within the text}

Citations within the text should be numbered consecutively. The corresponding
number is to appear enclosed in square brackets, such as [1] or [2]-[5]. The
corresponding references are to be listed in the same order at the end of the
paper, in the \textbf{References} section. (Note: the standard
\textsc{Bib\TeX} style \texttt{unsrt} produces this.) As to the format of the
references themselves, any style is acceptable as long as it is used
consistently.

As submission is double blind, refer to your own published work in the 
third person. That is, use ``In the previous work of Jones et al.\ [4]'',
not ``In our previous work [4]''. If you cite your other papers that
are not widely available (e.g.\ a journal paper under review), use
anonymous author names in the citation, e.g.\ an author of the
form ``A.\ Anonymous''. 


\subsection{Footnotes}

Indicate footnotes with a number\footnote{Sample of the first footnote} in the
text. Place the footnotes at the bottom of the page on which they appear.
Precede the footnote with a horizontal rule of 2~inches
(12~picas).\footnote{Sample of the second footnote}

\subsection{Figures}

All artwork must be neat, clean, and legible. Lines should be dark
enough for purposes of reproduction; art work should not be
hand-drawn. The figure number and caption always appear after the
figure. Place one line space before the figure caption, and one line
space after the figure. The figure caption is lower case (except for
first word and proper nouns); figures are numbered consecutively.

Make sure the figure caption does not get separated from the figure.
Leave sufficient space to avoid splitting the figure and figure caption.

You may use color figures. 
However, it is best for the
figure captions and the paper body to make sense if the paper is printed
either in black/white or in color.
\begin{figure}[h]
\begin{center}
%\framebox[4.0in]{$\;$}
\fbox{\rule[-.5cm]{0cm}{4cm} \rule[-.5cm]{4cm}{0cm}}
\end{center}
\caption{Sample figure caption.}
\end{figure}

\subsection{Tables}

All tables must be centered, neat, clean and legible. Do not use hand-drawn
tables. The table number and title always appear before the table. See
Table~\ref{sample-table}.

Place one line space before the table title, one line space after the table
title, and one line space after the table. The table title must be lower case
(except for first word and proper nouns); tables are numbered consecutively.

\begin{table}[t]
\caption{Sample table title}
\label{sample-table}
\begin{center}
\begin{tabular}{ll}
\multicolumn{1}{c}{\bf PART}  &\multicolumn{1}{c}{\bf DESCRIPTION}
\\ \hline \\
Dendrite         &Input terminal \\
Axon             &Output terminal \\
Soma             &Cell body (contains cell nucleus) \\
\end{tabular}
\end{center}
\end{table}

\section{Final instructions}
Do not change any aspects of the formatting parameters in the style files.
In particular, do not modify the width or length of the rectangle the text
should fit into, and do not change font sizes (except perhaps in the
\textbf{References} section; see below). Please note that pages should be
numbered.

\section{Preparing PostScript or PDF files}

Please prepare PostScript or PDF files with paper size ``US Letter'', and
not, for example, ``A4''. The -t
letter option on dvips will produce US Letter files.

Fonts were the main cause of problems in the past years. Your PDF file must
only contain Type 1 or Embedded TrueType fonts. Here are a few instructions
to achieve this.

\begin{itemize}

\item You can check which fonts a PDF files uses.  In Acrobat Reader,
select the menu Files$>$Document Properties$>$Fonts and select Show All Fonts. You can
also use the program \verb+pdffonts+ which comes with \verb+xpdf+ and is
available out-of-the-box on most Linux machines.

\item The IEEE has recommendations for generating PDF files whose fonts
are also acceptable for NIPS. Please see
\url{http://www.emfield.org/icuwb2010/downloads/IEEE-PDF-SpecV32.pdf}

\item LaTeX users:

\begin{itemize}

\item Consider directly generating PDF files using \verb+pdflatex+
(especially if you are a MiKTeX user). 
PDF figures must be substituted for EPS figures, however.

\item Otherwise, please generate your PostScript and PDF files with the following commands:
\begin{verbatim} 
dvips mypaper.dvi -t letter -Ppdf -G0 -o mypaper.ps
ps2pdf mypaper.ps mypaper.pdf
\end{verbatim}

Check that the PDF files only contains Type 1 fonts. 
%For the final version, please send us both the Postscript file and
%the PDF file. 

\item xfig "patterned" shapes are implemented with 
bitmap fonts.  Use "solid" shapes instead. 
\item The \verb+\bbold+ package almost always uses bitmap
fonts.  You can try the equivalent AMS Fonts with command
\begin{verbatim}
\usepackage[psamsfonts]{amssymb}
\end{verbatim}
 or use the following workaround for reals, natural and complex: 
\begin{verbatim}
\newcommand{\RR}{I\!\!R} %real numbers
\newcommand{\Nat}{I\!\!N} %natural numbers 
\newcommand{\CC}{I\!\!\!\!C} %complex numbers
\end{verbatim}

\item Sometimes the problematic fonts are used in figures
included in LaTeX files. The ghostscript program \verb+eps2eps+ is the simplest
way to clean such figures. For black and white figures, slightly better
results can be achieved with program \verb+potrace+.
\end{itemize}
\item MSWord and Windows users (via PDF file):
\begin{itemize}
\item Install the Microsoft Save as PDF Office 2007 Add-in from
\url{http://www.microsoft.com/downloads/details.aspx?displaylang=en\&familyid=4d951911-3e7e-4ae6-b059-a2e79ed87041}
\item Select ``Save or Publish to PDF'' from the Office or File menu
\end{itemize}
\item MSWord and Mac OS X users (via PDF file):
\begin{itemize}
\item From the print menu, click the PDF drop-down box, and select ``Save
as PDF...''
\end{itemize}
\item MSWord and Windows users (via PS file):
\begin{itemize}
\item To create a new printer
on your computer, install the AdobePS printer driver and the Adobe Distiller PPD file from
\url{http://www.adobe.com/support/downloads/detail.jsp?ftpID=204} {\it Note:} You must reboot your PC after installing the
AdobePS driver for it to take effect.
\item To produce the ps file, select ``Print'' from the MS app, choose
the installed AdobePS printer, click on ``Properties'', click on ``Advanced.''
\item Set ``TrueType Font'' to be ``Download as Softfont''
\item Open the ``PostScript Options'' folder
\item Select ``PostScript Output Option'' to be ``Optimize for Portability''
\item Select ``TrueType Font Download Option'' to be ``Outline''
\item Select ``Send PostScript Error Handler'' to be ``No''
\item Click ``OK'' three times, print your file.
\item Now, use Adobe Acrobat Distiller or ps2pdf to create a PDF file from
the PS file. In Acrobat, check the option ``Embed all fonts'' if
applicable.
\end{itemize}

\end{itemize}
If your file contains Type 3 fonts or non embedded TrueType fonts, we will
ask you to fix it. 

\subsection{Margins in LaTeX}
 
Most of the margin problems come from figures positioned by hand using
\verb+\special+ or other commands. We suggest using the command
\verb+\includegraphics+
from the graphicx package. Always specify the figure width as a multiple of
the line width as in the example below using .eps graphics
\begin{verbatim}
   \usepackage[dvips]{graphicx} ... 
   \includegraphics[width=0.8\linewidth]{myfile.eps} 
\end{verbatim}
or % Apr 2009 addition
\begin{verbatim}
   \usepackage[pdftex]{graphicx} ... 
   \includegraphics[width=0.8\linewidth]{myfile.pdf} 
\end{verbatim}
for .pdf graphics. 
See section 4.4 in the graphics bundle documentation (\url{http://www.ctan.org/tex-archive/macros/latex/required/graphics/grfguide.ps}) 
 
A number of width problems arise when LaTeX cannot properly hyphenate a
line. Please give LaTeX hyphenation hints using the \verb+\-+ command.


\subsubsection*{Acknowledgments}

Use unnumbered third level headings for the acknowledgments. All
acknowledgments go at the end of the paper. Do not include 
acknowledgments in the anonymized submission, only in the 
final paper. 

\subsubsection*{References}

References follow the acknowledgments. Use unnumbered third level heading for
the references. Any choice of citation style is acceptable as long as you are
consistent. It is permissible to reduce the font size to `small' (9-point) 
when listing the references. {\bf Remember that this year you can use
a ninth page as long as it contains \emph{only} cited references.}

\small{
[1] Alexander, J.A. \& Mozer, M.C. (1995) Template-based algorithms
for connectionist rule extraction. In G. Tesauro, D. S. Touretzky
and T.K. Leen (eds.), {\it Advances in Neural Information Processing
Systems 7}, pp. 609-616. Cambridge, MA: MIT Press.

[2] Bower, J.M. \& Beeman, D. (1995) {\it The Book of GENESIS: Exploring
Realistic Neural Models with the GEneral NEural SImulation System.}
New York: TELOS/Springer-Verlag.

[3] Hasselmo, M.E., Schnell, E. \& Barkai, E. (1995) Dynamics of learning
and recall at excitatory recurrent synapses and cholinergic modulation
in rat hippocampal region CA3. {\it Journal of Neuroscience}
{\bf 15}(7):5249-5262.
}

\end{document}
